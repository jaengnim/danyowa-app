import { GoogleGenAI, Modality } from '@google/genai';
import { VoiceName } from '../types';

// Base64 decode helper
function decode(base64: string): Uint8Array {
  const binaryString = atob(base64);
  const bytes = new Uint8Array(binaryString.length);
  for (let i = 0; i < binaryString.length; i++) {
    bytes[i] = binaryString.charCodeAt(i);
  }
  return bytes;
}

// PCM to AudioBuffer decoder
async function decodeAudioData(
  pcmData: Uint8Array,
  audioContext: AudioContext,
  sampleRate: number,
  numChannels: number
): Promise<AudioBuffer> {
  const numSamples = pcmData.length / 2;
  const audioBuffer = audioContext.createBuffer(numChannels, numSamples, sampleRate);
  const channelData = audioBuffer.getChannelData(0);

  for (let i = 0; i < numSamples; i++) {
    const sample = (pcmData[i * 2] | (pcmData[i * 2 + 1] << 8));
    channelData[i] = sample < 32768 ? sample / 32768 : (sample - 65536) / 32768;
  }

  return audioBuffer;
}

export const playAnnouncement = async (
  text: string,
  voiceName: VoiceName,
  onStart?: () => void,
  onEnd?: () => void,
  existingContext?: AudioContext
) => {
  try {
    // Vite í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ì½ê¸°
    const apiKey = import.meta.env.VITE_API_KEY || '';

    console.log('API Key í™•ì¸:', {
      length: apiKey?.length || 0,
      exists: !!apiKey,
      prefix: apiKey ? apiKey.substring(0, 10) + '...' : 'EMPTY'
    });

    if (!apiKey) {
      const msg = "âŒ API Key ì˜¤ë¥˜\n\n[Vercel ì„¤ì • í™•ì¸]\n1. Project Settings â†’ Environment Variables\n2. Key: VITE_API_KEY\n3. Value: ì‹¤ì œ Gemini API í‚¤ ì…ë ¥\n4. Redeploy ì‹¤í–‰";
      console.error(msg);
      alert(msg);
      if (onEnd) onEnd();
      return;
    }

    const audioContext = existingContext || new (window.AudioContext || (window as any).webkitAudioContext)();

    if (audioContext.state === 'suspended') {
      await audioContext.resume();
    }

    const ai = new GoogleGenAI({ apiKey: apiKey });

    const response = await ai.models.generateContent({
      model: "gemini-2.5-flash-preview-tts",
      contents: [{ parts: [{ text }] }],
      config: {
        responseModalities: [Modality.AUDIO],
        speechConfig: {
          voiceConfig: {
            prebuiltVoiceConfig: { voiceName },
          },
        },
      },
    });

    const base64Audio = response.candidates?.[0]?.content?.parts?.[0]?.inlineData?.data;

    if (!base64Audio) {
      throw new Error("Geminië¡œë¶€í„° ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.");
    }

    const audioBuffer = await decodeAudioData(
      decode(base64Audio),
      audioContext,
      24000,
      1
    );

    const source = audioContext.createBufferSource();
    source.buffer = audioBuffer;
    source.connect(audioContext.destination);

    source.onended = () => {
      if (onEnd) onEnd();
      if (!existingContext) {
        audioContext.close();
      }
    };

    if (onStart) onStart();
    source.start();

  } catch (error: any) {
    console.error("âŒ ì¬ìƒ ì˜¤ë¥˜:", error);

    // ì—ëŸ¬ ë©”ì‹œì§€ ë¶„ì„
    const errorMsg = error.message || JSON.stringify(error);

    if (errorMsg.includes('429') || errorMsg.includes('RESOURCE_EXHAUSTED')) {
      // í• ë‹¹ëŸ‰ ì´ˆê³¼ ì—ëŸ¬
      alert("ğŸ˜… AI ëª©ì†Œë¦¬ê°€ ì ì‹œ ì‰¬ê³  ìˆì–´ìš”.\n(1ë¶„ ë’¤ì— ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”)");
    } else if (errorMsg.includes('API Key')) {
      // API í‚¤ ê´€ë ¨ ì—ëŸ¬ëŠ” ê·¸ëŒ€ë¡œ í‘œì‹œ (ì„¤ì • í•„ìš”í•˜ë¯€ë¡œ)
      alert(`API ì„¤ì • ì˜¤ë¥˜:\n${errorMsg}`);
    } else {
      // ê¸°íƒ€ ì—ëŸ¬ëŠ” ê°„ë‹¨í•˜ê²Œ í‘œì‹œ
      console.warn('TTS ì¬ìƒ ì‹¤íŒ¨:', errorMsg);
      // ë„ˆë¬´ ì¦ì€ ì—ëŸ¬ íŒì—… ë°©ì§€ (í•„ìš”í•˜ë©´ ì£¼ì„ í•´ì œ)
      // alert("ìŒì„± ì•ˆë‚´ë¥¼ ì¬ìƒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.");
    }

    if (onEnd) onEnd();
  }
};